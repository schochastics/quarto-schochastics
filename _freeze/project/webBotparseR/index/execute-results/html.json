{
  "hash": "e8969328637b1fa6cc8f06c495172ff2",
  "result": {
    "markdown": "---\nauthor: David Schoch\ndate: \"2023-03-31\"\ndescription: \"Parse search engine results which have been scraped with the 'WebBot' browser extension\"\nsubtitle: Parse search engine results\ntitle: webBotparseR\nimage: featured-hex.png\ntitle-block-style: none\ntoc: true\npriority: 13\n---\n\n\n\n\n<button type=\"button\" class=\"btn btn-outline-success\"><a href=\"https://github.com/schochastics/webBotparseR\">GITHUB</a></button>\n\nwebbotparseR allows to parse search engine results that where scraped\nwith the [WebBot](https://github.com/gesiscss/WebBot) browser extension.\nA similar python library is [also\navailable](https://github.com/gesiscss/WebBot-tutorials).\n\n## Installation\n\nYou can install the development version of webbotparseR like so:\n\n``` r\nremotes::install_github(\"schochastics/webbotparseR\")\n```\n\nThe package contains an example html from a google search on climate\nchange.\n\n``` r\nlibrary(webbotparseR)\nex_file <- system.file(\"www.google.com_climatechange_text_2023-03-16_08_16_11.html\", package = \"webbotparseR\")\n```\n\nSuch search results can be parsed via the function\n`parse_search_results()`. The parameter `engine` is used to specify the\nsearch engine and the search type.\n\n``` r\noutput <- parse_search_results(path = ex_file,engine = \"google text\")\noutput\n#> # A tibble: 10 × 10\n#>    title link  text  image page  posit…¹ searc…² type  query date               \n#>    <chr> <chr> <chr> <chr> <chr>   <int> <chr>   <chr> <chr> <dttm>             \n#>  1 What… http… Clim… data… 1           1 www.go… text  clim… 2023-03-16 08:16:11\n#>  2 Home… http… Vita… data… 1           2 www.go… text  clim… 2023-03-16 08:16:11\n#>  3 Vita… http… “Cli… data… 1           3 www.go… text  clim… 2023-03-16 08:16:11\n#>  4 Clim… http… In c… data… 1           4 www.go… text  clim… 2023-03-16 08:16:11\n#>  5 IPCC… http… The … data… 1           5 www.go… text  clim… 2023-03-16 08:16:11\n#>  6 Clim… http… Comp… data… 1           6 www.go… text  clim… 2023-03-16 08:16:11\n#>  7 Clim… http… Clim… <NA>  1           7 www.go… text  clim… 2023-03-16 08:16:11\n#>  8 UNFC… http… What… data… 1           8 www.go… text  clim… 2023-03-16 08:16:11\n#>  9 Clim… http… Clim… data… 1           9 www.go… text  clim… 2023-03-16 08:16:11\n#> 10 Caus… http… This… data… 1          10 www.go… text  clim… 2023-03-16 08:16:11\n#> # … with abbreviated variable names ¹​position, ²​search_engine\n```\n\nNote that images are always returned base64 encoded.\n\n``` r\noutput$image[1]\n#> [1] \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAIAAACQkWg2AAAABnRSTlMAAAAAAABupgeRAAAAMklEQVR4AWMAgYYG4hEdNJAHGoCIABvBJayhgcYaIAwaakCwydUA52MKYeeSCgZh4gMAXrJ9ASggqqAAAAAASUVORK5CYII=\"\n```\n\nThe function `base64_to_img()` can be used to decode the image and save\nit in an appropriate format.\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}